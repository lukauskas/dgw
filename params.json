{"name":"DGW","tagline":"Dynamic Genome Warping","body":"Dynamic Genome Warping (DGW)\r\n===============\r\n\r\n# Installation\r\n\r\n## Prerequisites\r\nDGW depends on `numpy`, `scipy`, `pandas==0.10.1`, `mlpy`, `pysam`, `fastcluster`, `matplotlib` and modified `mlpy` packages (see below).\r\n\r\n### MLPY\r\nDGW depends on modified version of MLPY, available from https://github.com/sauliusl/mlpy\r\nYou can install it by\r\n```\r\npip install cython\r\npip install -e git://github.com/sauliusl/mlpy.git#egg=mlpy\r\n```\r\nCython is required for compilation of mlpy from source.\r\nNote that mlpy depends on GSL (with header-files). \r\nPlease look for instructions on how to install it on your platform if the installation fails.\r\n\r\nOn ubuntu this can be installed by \r\n```\r\napt-get install libgsl0-dev\r\n```\r\n\r\n## Platform-specific instructions\r\n\r\n### Linux\r\nYou should be able to directly install DGW dependencies by using `pip` on linux:\r\n```\r\npip install numpy \r\npip install scipy \r\npip install pandas\r\npip install pysam \r\npip install fastcluster \r\npip install matplotlib\r\n```\r\nNote that some packages, e.g. `scipy` depend on dev versions of some of the GNU libraries, \r\nyou will likely to have to install them before proceeding, for instance, on ubuntu you will need to:\r\n```\r\napt-get install libblas-dev liblapack-dev gfortran\r\n```\r\nSimilarly, you can install `numpy` and `scipy` using apt-get (or other package manager) if you like.\r\n\r\nFinally install modified MLPY:\r\n```\r\npip install -e git://github.com/sauliusl/mlpy.git#egg=mlpy\r\n```\r\n\r\n### Mac OS X \r\nProbably the most reliable way of installing `numpy`, `scipy`, `pandas`, `matplotlib` and `pysam` is via MacPorts (https://www.macports.org/)\r\nThis can be achieved by\r\n\r\n```\r\nport install python27 py27-numpy py27-scipy py27-pandas py27-matplotlib py27-pysam \r\n```\r\n\r\nThen the remaining dependancies, `fastcluster` and `mlpy` can be installed from pip\r\n```\r\npip install fastcluster\r\npip install mlpy\r\n```\r\n\r\nAlternatively, Enthought Python Distribution can be used to install these packages (see instructions for Windows).\r\nHowever `matplotlib` may not work correctly as EPD does not install python as a framework\r\n\r\n### Windows\r\nIt is probably easiest to install `numpy`, `scipy`, `pandas` and `matplotlib` on Windows via Enthought python distribution. This distribution is free for academic use. See \r\nhttp://www.enthought.com/products/epd.php for instructions how to download and install it.\r\n\r\nUnfortunately EPD 7.3 ships with an outdated version of `pandas` package that is not compatible with DGW, therefore you would have to upgrade it using pip in order to run it.\r\n```\r\npip install --upgrade pandas\r\n```\r\n\r\nPackages that are not in EPD also need to be installed using pip\r\n```\r\npip install pysam fastcluster\r\n```\r\n\r\nif `fastcluster` install fails install it from source from http://github.com/sauliusl/fastcluster\r\n\r\nDon't forget MLPY:\r\n```\r\npip install -e git://github.com/sauliusl/mlpy.git#egg=mlpy\r\n```\r\n\r\n## Installing Python 2.7 to a non-root environment\r\nThe above steps need python to be installed on the system.\r\nIf you do not have Python2.7, you need to install it.\r\nThe following steps show how to install python to an environment on linux you do not have root access to.\r\n\r\n1. Download and extract Python sources:\r\n```\r\n$ wget http://www.python.org/ftp/python/2.7.3/Python-2.7.3.tgz\r\n$ tar xvf Python-2.7.3\r\n```\r\n2. Install python to local location\r\n```\r\n$ cd Python-2.7.3\r\n$ ./configure\r\n$ make altinstall prefix=~/python_dev/python/ exec-prefix=~/python_dev/python\r\n```\r\nwhere `~/python_dev/python` is the desired location to install python to (change as appropriate).\r\nNote the tilde (`~`) indicating this is under `$HOME` directory -- directory my user has access to.\r\n\r\nAt this point you should have a `python2.7` executable at `~/python_dev/python/bin/`.\r\n\r\n3. Set up PATH variables\r\n```\r\n$ export PATH=~/python_dev/python/bin:$PATH\r\n$ export PYTHONPATH=~/python_dev/python/lib/python2.7/site-packages/\r\n```\r\n\r\n4. Download and install setuptools. Make sure that your `PYTHONPATH` variable is set correctly before doing this.\r\n```\r\nwget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea\r\nsh setuptools-0.6c11-py2.7.egg\r\n```\r\n\r\n5. You now should be able to install pip by:\r\n```\r\neasy_install-2.7 pip\r\n```\r\n\r\n6. Once pip is installed, you can install dependencies for DGW as per linux installations step.\r\nMake sure you use the newly installed `pip-2.7`, which will be in your local directory and not the one that comes with system\r\n\r\n# Installation of DGW\r\n\r\nDGW has to be installed directly from the source. You can obtain source by cloning the DGW repository.\r\n\r\n```\r\ngit clone\r\n```\r\n\r\nIn order to be able to use DGW from any location in your system\r\nset up your PATH and PYTHONPATH variables to point to the location of the new repository, on unix this is done:\r\n```\r\nexport PYTHONPATH=$PYTHONPATH:/directory/where/dgw/is/checked/out\r\nexport PATH=$PATH:/directory/where/dgw/is/checked/out/bin\r\n```\r\nNote the \"bin\" in the end of PATH directory -- this is where the main executables of package lie in. \r\nYou may want to add these two lines to your `~/.bashrc` so they are executed every time you open your shell.\r\n\r\n# Usage\r\n\r\nDGW is split into two parts - computationally demanding part, `dgw-worker` and an exploratory part - `dgw-explorer`.\r\n\r\n## `dgw-worker`\r\n\r\nThe worker part of the module is responsible for the actual hard work done in clustering the data. It preprocesses the data, computes intermediate representations, calculates DTW distances between the data, performs hierarchical clustering and calculates prototypes of the clusters.\r\n\r\n### Sample usage\r\n\r\nTypically, `dgw-worker` would be run as follows:\r\n```\r\ndgw-worker.py -r tss_regions.bed  -d wgEncodeBroadHistoneK562H3k4me3StdAlnRep1.bam wgEncodeBroadHistoneK562Pol2bStdAlnRep1.bam --prefix dgw_example\r\n```\r\nIn this case we are providing a bed file of regions of interest we want to cluster (`-r tss_regions.bed`), two datasets to work on (`-d wgEncodeBroadHistoneK562H3k4me3StdAlnRep1.bam wgEncodeBroadHistoneK562Pol2bStdAlnRep1.bam`) and setting the prefix of files that will be output to `dgw_example`.\r\n\r\nThe DGW-worker will take all alignments from both datasets at regions in the `tss_regions.bed`. These alignments will then be extended and put into bins of 50 base pairs wide (use `-res` parameter to change this width).\r\nThen the unexpressed regions that have no bin with more than 10 reads in them (`-min-pileup` constraint to change) will be ignored. Note that these ignored regions are then saved to `{prefix}_filtered_regions.bed` file.\r\nThe remaining data will be normalised by adding two artificial reads for each bin and then taking the log of the number of reads in the bins.\r\nThe remaining regions will then be clustered hierarchically using DTW distance with default parameters.\r\n\r\n### Output\r\nThe worker will output 8 files to the working directory where `{prefix}` is the prefix specified by `--prefix` argument.\r\n\r\n* `{prefix}_config.dgw` -- The main file storing the configuration of DGW that was used to produce the other files.\r\n* `{prefix}_dataset.pd` -- Processed dataset after the normalisation. This can then be passed in a subsequent DGW session as `--processed-dataset` parameter.\r\n* `{prefix}_filtered_regions.bed` -- Regions that were filtered out of the original regions set due to preprocessing constraints.\r\n* `{prefix}_linkage.npy` -- Precomputed linkage matrix that is used in hierarchical clustering \r\n* `{prefix}_missing_regions.bed` -- regions that were in the BED file provided as an input, but were not in one of the BAM files.\r\n* `{prefix}_prototypes.pickle` -- computed prototypes of the clusters\r\n* `{prefix}_regions.pd` -- regions that were processed, saved in DGW-readable format\r\n* `{prefix}_warping_paths.pickle` -- computed warping paths of the original data projected onto prototypes\r\n\r\n### Points of interest\r\nIn some cases one would want to track some points of interest and their locations after warping. `dgw-worker` can also be run with a `-poi` parameter specified, for instance:\r\n\r\n```\r\ndgw-worker.py -r tss_regions.bed -poi first_splicing_site_locations.bed  -d wgEncodeBroadHistoneK562H3k4me3StdAlnRep1.bam wgEncodeBroadHistoneK562Pol2bStdAlnRep1.bam --prefix dgw_example\r\n```\r\n\r\nThe regions in `first_splicing_site_locations.bed` must have the same names as the regions in `tss_regions.bed` otherwise DGW won't be able to match them. Also have a look at `--ignore-poi-non-overlaps` id some of the regions in the input file may not contain some of the regions listed as points of interest.\r\nSimilarly, `--ignore-no-poi-regions` will make DGW ignore those regions in input file that do not contain any of the points of interest provided.\r\n\r\n### Runtime\r\nPlease note that DGW Worker is a very computationally-demanding piece of software.\r\nIt is designed to be used on a performant computer with as much CPU cores as possible.\r\n\r\nA good way to estimate how long will the computation take on your machine is to use `--random-sample` parameter, e.g. pass `--random-sample 1000`.\r\nThis parameter will take only a random sample of N regions, where N is the provided number (e.g. 1000). \r\nThe DGW worker will work on this random sample and report you both the time it took to compute the pairwise distances\r\non the random sample, and the estimated time to compute them on the full sample. \r\n\r\nPrototype estimation and DTW projections onto prototypes will take around an extra 50% of time taken for pairwise distance calculations.\r\n\r\n## `dgw-explorer.py`\r\n\r\nA second major part of DGW is the DGW explorer. \r\nThis software is much less computationally demanding than DGW Worker and is designed to allow you to explore the results.\r\n\r\nIn order to use it start it by passing a `{prefix}_config.dgw` file computed by \r\nDGW worker:\r\n``dgw-explorer.py dgw_config.dgw``\r\n\r\nThe remaining files output by DGW explorer must be in the same directory as the `dgw_config.dgw` file, otherwise the explorer will not be able to locate them.\r\n\r\nUpon successful start, a window showing the dendrogram and heatmap will pop up. Left click on the dendrogram to cut it at the desired place, wait for the plot to refresh and click preview to bring up a cluster explorer.\r\n\r\nThe cluster explorer allows you to cycle through clusters generated by the dendrogram cut and save both the data of the clusters and the generated heatmaps.\r\n\r\nNote that you can also provide `-poi` parameter to `dgw-explorer.py`. \r\nThis will override the points of interest specified by worker.\r\nDGW Explorer allows you to specify up to two sets of points of interest (just add the -poi parameter twice). \r\n\r\nThe resulting points of interest will be plotted on top of the heatmap in cluster viewer.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}